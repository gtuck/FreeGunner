name: Daily Article Researcher

on:
  schedule:
    - cron: "0 5 * * *"   # 5:00 AM UTC (daily)
  workflow_dispatch:
    inputs:
      force_refresh:
        description: 'Force refresh all feeds (ignore history)'
        required: false
        default: false
        type: boolean
      debug_mode:
        description: 'Enable debug logging'
        required: false
        default: false
        type: boolean

permissions:
  contents: write
  actions: read

jobs:
  fetch-articles:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    env:
      # Configuration (overridable in .env)
      DOTENV_PATH: .env
      FEEDS_FILE: feeds.json
      HISTORY_FILE: history.json
      OUTPUT_DIR: articles
      RESULTS_PER_QUERY: "10"
      USER_AGENT: "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125 Safari/537.36"
      DEFAULT_RSS: "https://www.firearmsnews.com/RSS.aspx?websiteid=77508&listingid=77589"
      
      # Workflow inputs
      FORCE_REFRESH: ${{ github.event.inputs.force_refresh || 'false' }}
      DEBUG_MODE: ${{ github.event.inputs.debug_mode || 'false' }}
      
      # 🔐 API credentials from secrets
      GCS_API_KEY: ${{ secrets.GCS_API_KEY }}
      GCS_CX: ${{ secrets.GCS_CX }}

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 1

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"
          cache: "pip"

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Validate configuration
        run: |
          echo "🔍 Validating configuration..."
          python -c "
          import os
          import json
          from pathlib import Path
          
          # Check if feeds file exists and is valid
          feeds_file = os.getenv('FEEDS_FILE', 'feeds.json')
          if Path(feeds_file).exists():
              try:
                  with open(feeds_file) as f:
                      feeds = json.load(f)
                  print(f'✅ Found {len(feeds)} feeds in {feeds_file}')
              except Exception as e:
                  print(f'❌ Invalid feeds file: {e}')
                  exit(1)
          else:
              print(f'⚠️  Feeds file {feeds_file} not found, will create default')
          
          # Check API credentials
          if os.getenv('GCS_API_KEY') and os.getenv('GCS_CX'):
              print('✅ Google Custom Search credentials configured')
          else:
              print('⚠️  Google Custom Search not configured - research will be limited')
          "

      - name: Run article fetcher
        id: fetch
        run: |
          echo "🚀 Starting article fetch process..."
          python scripts/fetch_articles.py

      - name: Upload logs as artifact
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: fetch-logs-${{ github.run_number }}
          path: |
            fetch_articles.log
            *.log
          retention-days: 7

      - name: Check for rate limiting
        if: failure()
        run: |
          echo "::warning title=Rate Limiting Check::If this job failed due to rate limiting, consider:"
          echo "- Reducing RESULTS_PER_QUERY"
          echo "- Adding delays between requests"
          echo "- Using different API keys or services"

      - name: Commit and push changes
        if: steps.fetch.outputs.any_new == 'true'
        run: |
          echo "📝 Committing new articles..."
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action Bot"
          
          # Add only the files we care about
          git add "${OUTPUT_DIR}/" "${HISTORY_FILE}" || true
          
          if git diff --staged --quiet; then
            echo "No changes to commit."
          else
            # Create detailed commit message
            COMMIT_MSG="chore: add researched article(s) $(date -u +'%Y-%m-%d %H:%M UTC')"
            if [ "${{ github.event.inputs.force_refresh }}" = "true" ]; then
              COMMIT_MSG="$COMMIT_MSG (force refresh)"
            fi
            
            git commit -m "$COMMIT_MSG"
            git push
            
            echo "✅ Successfully committed and pushed changes"
          fi

      - name: Create issue on failure
        if: failure() && github.event_name == 'schedule'
        uses: actions/github-script@v7
        with:
          script: |
            const title = `Daily Article Fetcher Failed - ${new Date().toISOString().split('T')[0]}`;
            const body = `
            The daily article fetcher workflow failed.
            
            **Workflow Run:** ${{ github.server_url }}/${{ github.repository }}/actions/runs/${{ github.run_id }}
            **Triggered by:** ${{ github.event_name }}
            **Time:** ${{ github.event.head_commit.timestamp }}
            
            Please check the logs and resolve any issues.
            `;
            
            // Check if issue already exists
            const issues = await github.rest.issues.listForRepo({
              owner: context.repo.owner,
              repo: context.repo.repo,
              state: 'open',
              labels: 'workflow-failure'
            });
            
            const existingIssue = issues.data.find(issue => issue.title === title);
            
            if (!existingIssue) {
              await github.rest.issues.create({
                owner: context.repo.owner,
                repo: context.repo.repo,
                title: title,
                body: body,
                labels: ['workflow-failure', 'automated']
              });
            }
